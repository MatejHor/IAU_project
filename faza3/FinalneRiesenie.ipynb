{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3. fáza projektu\n",
    "## Matej Horniak, Lukáš Mikula\n",
    "Dátová sada č. 44"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute._iterative import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dateutil.parser as parser\n",
    "from sklearn.impute import SimpleImputer as Imputer, SimpleImputer\n",
    "from sklearn.neighbors import NearestNeighbors as neigh\n",
    "from sklearn.neighbors import KNeighborsRegressor as neigh\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from missingpy import KNNImputer, MissForest\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DataFrameWrapper():\n",
    "    def __init__(self, data, person):\n",
    "        self.data = data\n",
    "        self.person = person\n",
    "        self.merged_data = None\n",
    "        self.pipeline = None\n",
    "        self.numeric1 = None\n",
    "        self.numeric2 = None\n",
    "        self.categoric = None\n",
    "        self.preproccessors = None\n",
    "        \n",
    "    def getMergedData(self):\n",
    "        # Return DataFrame\n",
    "        return self.merged_data\n",
    "    \n",
    "    def setPersonOtherData(self, data, person):\n",
    "        # Set new data to data and person DataFrame\n",
    "        # Other variable set to None\n",
    "        self.data = data\n",
    "        self.person = person\n",
    "        self.merged_data = None\n",
    "        self.numeric1 = None\n",
    "        self.numeric2 = None\n",
    "        self.categoric = None\n",
    "        return self\n",
    "    \n",
    "    def prepocessing(self):\n",
    "        # Prepocessing data\n",
    "        # Remove medical_info, merge other and person DataFrame\n",
    "        # Remove duplicate\n",
    "        # Modify data to unit format\n",
    "        \n",
    "        dict_array = []\n",
    "        string = '{\"mean_glucose\": 9999999,\"std_glucose\": 9999999,\"kurtosis_glucose\":9999999,\"skewness_glucose\":9999999,\"mean_oxygen\":9999999,\"std_oxygen\":9999999,\"kurtosis_oxygen\":9999999,\"skewness_oxygen\":9999999}'\n",
    "        self.data.medical_info.apply(lambda x: dict_array.append(json.loads(x.replace(\"'\",\"\\\"\").replace(\":\\\"\",\":\").replace(\"\\\",\",\",\").replace(\"\\\"}\",\"}\") if isinstance(x,str) else string)))\n",
    "        medical_datas = pd.DataFrame(dict_array)\n",
    "        \n",
    "        for item in medical_datas:\n",
    "            self.data[item] = medical_datas[item].astype(float)\n",
    "        self.data = self.data.drop(columns=['medical_info'])\n",
    "        \n",
    "        self.data = self.data.replace({ 9999999 : np.nan },regex=False)\n",
    "        self.data = self.data.replace({'^[? ]*$' : np.nan},regex=True)\n",
    "        self.person = self.person.replace({'^[? ]*$' : np.nan},regex=True)\n",
    "        self.og = copy.deepcopy(self.data) \n",
    "        \n",
    "        numeric = self.data.select_dtypes(include=['float64'])\n",
    "        categoric = self.data.select_dtypes(include=['object'])\n",
    "        numeric['name'] = categoric['name']\n",
    "        \n",
    "        numeric = numeric.groupby('name').aggregate('mean')\n",
    "        categoric = categoric.groupby('name').aggregate('first')\n",
    "        \n",
    "        self.data = categoric.merge(numeric, on=['name'])\n",
    "        \n",
    "        self.merged_data = pd.merge(self.person, self.data, on=['name','address'], how='left')\n",
    "        \n",
    "        self.merged_data = self.merged_data.replace(['FALSE','F'],'f',regex=True)\n",
    "        self.merged_data = self.merged_data.replace(['TRUE','T'],'t',regex=True)\n",
    "        \n",
    "        self.merged_data = self.merged_data.replace([' <=50K'],'<=50K',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' >50K'],'>50K',regex=True)\n",
    "    \n",
    "    \n",
    "        self.merged_data = self.merged_data.replace([' Other-relative'],'Other_relative',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' Not-in-family'],'Not_in_family',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' Own-child'],'Own_child',regex=True)\n",
    "        \n",
    "        \n",
    "        for i, row in self.merged_data.iterrows():\n",
    "                \n",
    "            date = parser.parse(self.merged_data.iloc[i]['date_of_birth'].split(' ')[0])\n",
    "            day = date.day\n",
    "            month = date.month\n",
    "            year = date.year\n",
    "            \n",
    "            if (year > 2019):\n",
    "                year = year - 100\n",
    "        \n",
    "            self.merged_data.at[i,'date_of_birth'] = str(day) + \"/\" + str(month) + \"/\" + str(year)\n",
    "                    \n",
    "            if ((pd.isna(row['age'])) | (row['age'] > 115) | (row['age'] < 0)):\n",
    "                self.merged_data.at[i,'age'] = 2019 - year\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def removeOutliers(self):\n",
    "        # Remove outliers on floats datas\n",
    "        \n",
    "        ## Remove outliers from 'kurtosis_glucose'\n",
    "        column = 'kurtosis_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 6) | (self.merged_data[column] < -1)\n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'mean_glucose'\n",
    "        column = 'mean_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 150)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'mean_oxygen'\n",
    "        column = 'mean_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 120)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'kurtosis_oxygen'\n",
    "        column = 'kurtosis_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 20)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'skewness_glucose'\n",
    "        column = 'skewness_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 40)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'skewness_oxygen'\n",
    "        column = 'skewness_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 350)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'std_glucose'\n",
    "        column = 'std_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 62) \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'std_oxygen'\n",
    "        column = 'std_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 80)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def overtypeData(self):\n",
    "        # Change data type of object to float64\n",
    "        # From pipeline\n",
    "        \n",
    "        self.merged_data['age'] = self.merged_data['age'].astype(np.float64)\n",
    "        self.merged_data['education-num'] = self.merged_data['education-num'].astype(np.float64)\n",
    "        self.merged_data['capital-gain'] = self.merged_data['capital-gain'].astype(np.float64)\n",
    "        self.merged_data['fnlwgt'] = self.merged_data['fnlwgt'].astype(np.float64)\n",
    "        # self.merged_data['class'] = self.merged_data['class'].astype(np.float64)\n",
    "        self.merged_data['hours-per-week'] = self.merged_data['hours-per-week'].astype(np.float64)\n",
    "        self.merged_data['capital-loss'] = self.merged_data['capital-loss'].astype(np.float64)\n",
    "        self.merged_data['mean_glucose'] = self.merged_data['mean_glucose'].astype(np.float64)\n",
    "        self.merged_data['std_glucose'] = self.merged_data['std_glucose'].astype(np.float64)\n",
    "        self.merged_data['kurtosis_glucose'] = self.merged_data['kurtosis_glucose'].astype(np.float64)\n",
    "        self.merged_data['skewness_glucose'] = self.merged_data['skewness_glucose'].astype(np.float64)\n",
    "        self.merged_data['mean_oxygen'] = self.merged_data['mean_oxygen'].astype(np.float64)\n",
    "        self.merged_data['std_oxygen'] = self.merged_data['std_oxygen'].astype(np.float64)\n",
    "        self.merged_data['kurtosis_oxygen'] = self.merged_data['kurtosis_oxygen'].astype(np.float64)\n",
    "        self.merged_data['skewness_oxygen'] = self.merged_data['skewness_oxygen'].astype(np.float64)\n",
    "        self.merged_data['class'] = self.person['class']\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def divideData(self):\n",
    "        # Divide train data into 3 category\n",
    "        # Remove age and append on the end of DataFrame\n",
    "        # Remove class\n",
    "        \n",
    "        self.person['class'] = self.merged_data['class']\n",
    "        self.merged_data = self.merged_data.drop(columns=['class'])\n",
    "        age_column = copy.deepcopy(self.merged_data['age'])\n",
    "        self.merged_data = self.merged_data.drop(columns=['age'])\n",
    "        self.merged_data['age'] = age_column\n",
    "\n",
    "        numeric = self.merged_data.select_dtypes(include=['float64'])\n",
    "        self.numeric1 = numeric.iloc[:,:5].columns\n",
    "        # print(numeric1)\n",
    "        self.numeric2 = numeric.iloc[:,5:].columns\n",
    "        # print(numeric2)  \n",
    "        self.categoric = self.merged_data.select_dtypes(include=['object']).columns\n",
    "        # print(categoric)\n",
    "        return self\n",
    "    \n",
    "    def createPipelineSteps(self):\n",
    "        # Create pipeline steps, for categoric mostfrequent strategy\n",
    "        # For numeric KNN, MissForest\n",
    "        \n",
    "        numeric_transformer1 = Pipeline(steps=[('imputer',MissForest(missing_values=np.NaN, max_iter=10, # Nahradenie nulovych hodnot pomocou MissForest\n",
    "                                                                     decreasing=False, copy=False)), \n",
    "                                              ('powerTransformer',PowerTransformer(method='yeo-johnson',\n",
    "                                                                                   copy=False)) # Transformuje dat aby boli viac z Gaussoveho rozdelenia\n",
    "                                               ])\n",
    "        numeric_transformer2 = Pipeline(steps=[('imputer',KNNImputer(missing_values=np.NaN, n_neighbors=5, # Nahradenie nulovych hodnot pomocou KNN\n",
    "                                                                      weights='distance')), \n",
    "                                             # ('RobustScaler',StandardScaler())    # \n",
    "                                               ])\n",
    "        self.categoric_transormer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))]) # Nahradenie nulovych hodnot pomocou najcastejsich hodnot\n",
    "                                              # ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "        preproccesors = ColumnTransformer(transformers=[('Cat', self.categoric_transormer, self.categoric),\n",
    "                                                        ('Num1', numeric_transformer1, self.numeric1),\n",
    "                                                        ('Num2', numeric_transformer2, self.numeric2)\n",
    "                                                        ])\n",
    "        self.preproccessors = preproccesors\n",
    "        return self\n",
    "    \n",
    "    def appendPipelineSteps(self):\n",
    "        # Create Pipeline with steps\n",
    "        \n",
    "        if self.pipeline is None:\n",
    "            print(\"create Pipeline\")\n",
    "            self.pipeline = Pipeline(steps=[('preproccesors', self.preproccessors)])\n",
    "        else:\n",
    "            print(\"append Steps\")\n",
    "            self.pipeline.steps.append([('preproccesors', self.preproccessors)])\n",
    "        return self\n",
    "    \n",
    "    def popSteps(self):\n",
    "        self.pipeline.steps.pop()\n",
    "        return self\n",
    "    \n",
    "    def Fit(self):\n",
    "        # Use fit in pipeline\n",
    "        \n",
    "        self.pipeline.fit(self.merged_data)\n",
    "        # self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    \n",
    "    def FitTransform(self):\n",
    "        # Use fit and transform in pipeline\n",
    "        \n",
    "        pipeline_datas = self.pipeline.fit_transform(self.merged_data)\n",
    "        self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    \n",
    "    def Transform(self):\n",
    "        # Use transform in pipeline\n",
    "        \n",
    "        pipeline_datas = self.pipeline.transform(self.merged_data)\n",
    "        self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load csv files\n",
    "\n",
    "data = pd.read_csv(\"../data/other_train.csv\",index_col=0)\n",
    "person = pd.read_csv(\"../data/personal_train.csv\",index_col=0)\n",
    "\n",
    "\n",
    "val_data = pd.read_csv(\"../data/other_valid.csv\",index_col=0)\n",
    "val_person = pd.read_csv(\"../data/personal_valid.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:224: UserWarning: There are rows with more than 50.0% missing values. These rows are not included as donor neighbors.\n  .format(self.row_max_missing * 100))\n/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n  .format(self.row_max_missing * 100))\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n  return distances if squared else np.sqrt(distances, out=distances)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n  .format(self.row_max_missing * 100))\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n  return distances if squared else np.sqrt(distances, out=distances)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "create Pipeline\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<__main__.DataFrameWrapper at 0x7f43e51dbe48>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# Active train data processing\n",
    "\n",
    "wrapper = DataFrameWrapper(data,person)\n",
    "wrapper.prepocessing().removeOutliers().divideData().createPipelineSteps().appendPipelineSteps()\\\n",
    "                        .Fit().Transform()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3933 entries, 0 to 3932\nData columns (total 28 columns):\nname                3933 non-null object\naddress             3933 non-null object\nsex                 3933 non-null object\ndate_of_birth       3933 non-null object\nrace                3933 non-null object\nmarital-status      3933 non-null object\noccupation          3933 non-null object\npregnant            3933 non-null object\nrelationship        3933 non-null object\neducation           3933 non-null object\nincome              3933 non-null object\nnative-country      3933 non-null object\nworkclass           3933 non-null object\neducation-num       3933 non-null float64\ncapital-gain        3933 non-null float64\nfnlwgt              3933 non-null float64\nhours-per-week      3933 non-null float64\ncapital-loss        3933 non-null float64\nkurtosis_glucose    3933 non-null float64\nkurtosis_oxygen     3933 non-null float64\nmean_glucose        3933 non-null float64\nmean_oxygen         3933 non-null float64\nskewness_glucose    3933 non-null float64\nskewness_oxygen     3933 non-null float64\nstd_glucose         3933 non-null float64\nstd_oxygen          3933 non-null float64\nage                 3933 non-null float64\nclass               3933 non-null float64\ndtypes: float64(15), object(13)\nmemory usage: 860.4+ KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Show training data, and save into trained_datas.csv\n",
    "\n",
    "merged_data = wrapper.overtypeData().getMergedData()\n",
    "merged_data.info()\n",
    "merged_data.to_csv('trained_datas.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n  .format(self.row_max_missing * 100))\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Use pipeline to transform on valid data\n",
    "\n",
    "wrapper.setPersonOtherData(val_data,val_person).prepocessing().removeOutliers().divideData()\n",
    "wrapper.Transform().overtypeData()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1311 entries, 0 to 1310\nData columns (total 28 columns):\nname                1311 non-null object\naddress             1311 non-null object\nsex                 1311 non-null object\ndate_of_birth       1311 non-null object\nrace                1311 non-null object\nmarital-status      1311 non-null object\noccupation          1311 non-null object\npregnant            1311 non-null object\nrelationship        1311 non-null object\neducation           1311 non-null object\nincome              1311 non-null object\nnative-country      1311 non-null object\nworkclass           1311 non-null object\neducation-num       1311 non-null float64\ncapital-gain        1311 non-null float64\nfnlwgt              1311 non-null float64\nhours-per-week      1311 non-null float64\ncapital-loss        1311 non-null float64\nkurtosis_glucose    1311 non-null float64\nkurtosis_oxygen     1311 non-null float64\nmean_glucose        1311 non-null float64\nmean_oxygen         1311 non-null float64\nskewness_glucose    1311 non-null float64\nskewness_oxygen     1311 non-null float64\nstd_glucose         1311 non-null float64\nstd_oxygen          1311 non-null float64\nage                 1311 non-null float64\nclass               1309 non-null float64\ndtypes: float64(15), object(13)\nmemory usage: 286.9+ KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Show valid data. and save into validate_datas.csv\n",
    "\n",
    "wrapper.getMergedData().to_csv('validate_datas.csv')\n",
    "wrapper.getMergedData().info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-938d843a",
   "language": "python",
   "display_name": "PyCharm (IAU)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}