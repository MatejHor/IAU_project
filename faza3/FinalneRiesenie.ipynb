{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. fáza projektu\n",
    "## Matej Horniak, Lukáš Mikula\n",
    "Dátová sada č. 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "V tomto notebooku sme zaobalili funckie z predoslej fazy (preprocessingu dat) do wrapperu. \n",
    "\n",
    "Tieto funkcie spustame nad jednotlivymi datami a tieto upravene data si ukladame do pomocnych csv suborov, aby sme ich mohli dalej iba citat. Taktiez spracuvavame 5. bod tohto zadania, pricom najprv vytvorime data s pouzitim inych technik nahradzovania chybajucich dat. A vysledky 5. bodu tohto zadania. Tiez zhodnocujeme vysledky nasich manualne vytvorenych stromov so stromami vytvorenymi pomocou scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute._iterative import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dateutil.parser as parser\n",
    "from sklearn.impute import SimpleImputer as Imputer, SimpleImputer\n",
    "from sklearn.neighbors import NearestNeighbors as neigh\n",
    "from sklearn.neighbors import KNeighborsRegressor as neigh\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from missingpy import KNNImputer, MissForest\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataFrameWrapper():\n",
    "    def __init__(self, data, person):\n",
    "        self.data = data\n",
    "        self.person = person\n",
    "        self.merged_data = None\n",
    "        self.pipeline = None\n",
    "        self.numeric1 = None\n",
    "        self.numeric2 = None\n",
    "        self.categoric = None\n",
    "        self.preproccessors = None\n",
    "        \n",
    "    def getMergedData(self):\n",
    "        # Return DataFrame\n",
    "        return self.merged_data\n",
    "    \n",
    "    def setPersonOtherData(self, data, person):\n",
    "        # Set new data to data and person DataFrame\n",
    "        # Other variable set to None\n",
    "        self.data = data\n",
    "        self.person = person\n",
    "        self.merged_data = None\n",
    "        self.numeric1 = None\n",
    "        self.numeric2 = None\n",
    "        self.categoric = None\n",
    "        return self\n",
    "    \n",
    "    def prepocessing(self):\n",
    "        # Prepocessing data\n",
    "        # Remove medical_info, merge other and person DataFrame\n",
    "        # Remove duplicate\n",
    "        # Modify data to unit format\n",
    "        \n",
    "        dict_array = []\n",
    "        string = '{\"mean_glucose\": 9999999,\"std_glucose\": 9999999,\"kurtosis_glucose\":9999999,\"skewness_glucose\":9999999,\"mean_oxygen\":9999999,\"std_oxygen\":9999999,\"kurtosis_oxygen\":9999999,\"skewness_oxygen\":9999999}'\n",
    "        self.data.medical_info.apply(lambda x: dict_array.append(json.loads(x.replace(\"'\",\"\\\"\").replace(\":\\\"\",\":\").replace(\"\\\",\",\",\").replace(\"\\\"}\",\"}\") if isinstance(x,str) else string)))\n",
    "        medical_datas = pd.DataFrame(dict_array)\n",
    "        \n",
    "        for item in medical_datas:\n",
    "            self.data[item] = medical_datas[item].astype(float)\n",
    "        self.data = self.data.drop(columns=['medical_info'])\n",
    "        \n",
    "        self.data = self.data.replace({ 9999999 : np.nan },regex=False)\n",
    "        self.data = self.data.replace({'^[? ]*$' : np.nan},regex=True)\n",
    "        self.person = self.person.replace({'^[? ]*$' : np.nan},regex=True)\n",
    "        self.og = copy.deepcopy(self.data) \n",
    "        \n",
    "        numeric = self.data.select_dtypes(include=['float64'])\n",
    "        categoric = self.data.select_dtypes(include=['object'])\n",
    "        numeric['name'] = categoric['name']\n",
    "        \n",
    "        numeric = numeric.groupby('name').aggregate('mean')\n",
    "        categoric = categoric.groupby('name').aggregate('first')\n",
    "        \n",
    "        self.data = categoric.merge(numeric, on=['name'])\n",
    "        \n",
    "        self.merged_data = pd.merge(self.person, self.data, on=['name','address'], how='left')\n",
    "        \n",
    "        self.merged_data = self.merged_data.replace(['FALSE','F'],'f',regex=True)\n",
    "        self.merged_data = self.merged_data.replace(['TRUE','T'],'t',regex=True)\n",
    "        \n",
    "        self.merged_data = self.merged_data.replace([' <=50K'],'<=50K',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' >50K'],'>50K',regex=True)\n",
    "    \n",
    "    \n",
    "        self.merged_data = self.merged_data.replace([' Other-relative'],'Other_relative',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' Not-in-family'],'Not_in_family',regex=True)\n",
    "        self.merged_data = self.merged_data.replace([' Own-child'],'Own_child',regex=True)\n",
    "        \n",
    "        \n",
    "        for i, row in self.merged_data.iterrows():\n",
    "            day = 0\n",
    "            month = 0\n",
    "            year = 0\n",
    "            \n",
    "            try:\n",
    "                date = parser.parse(self.merged_data.iloc[i]['date_of_birth'].split(' ')[0])\n",
    "                day = date.day\n",
    "                month = date.month\n",
    "                year = date.year\n",
    "            except:\n",
    "                day = random.randint(1,31)\n",
    "                month = random.randint(1,12)\n",
    "                year = 2019 - row['age']\n",
    "#                 date = self.merged_data.iloc[i]['date_of_birth'].split(' ')[0]\n",
    "#                 date[0] = int(date[0])\n",
    "#                 date[1] = int(date[1])\n",
    "#                 date[2] = int(date[2])\n",
    "                \n",
    "                \n",
    "#                 if date[0] <= 12:\n",
    "#                     month = date[0]\n",
    "#                 elif date[0] <= 31:\n",
    "#                     day = date[0]\n",
    "#                 else:\n",
    "#                     year = date[0]\n",
    "                \n",
    "#                 if date[1] <= 12 and month is not 0:\n",
    "#                     month = date[1]\n",
    "#                 elif date[1] <= 31 and day is not 0:\n",
    "#                     day = date[1]\n",
    "#                 else:\n",
    "#                     year = date[1]\n",
    "                    \n",
    "#                 if date[2] <= 12 and month is not 0:\n",
    "#                     month = date[2]\n",
    "#                 elif date[2] <= 31 and day is not 0:\n",
    "#                     day = date[2]\n",
    "#                 else:\n",
    "#                     year = date[2]\n",
    "                \n",
    "            \n",
    "            \n",
    "            if (year > 2019):\n",
    "                year = year - 100\n",
    "        \n",
    "            self.merged_data.at[i,'date_of_birth'] = str(day) + \"/\" + str(month) + \"/\" + str(year)\n",
    "                    \n",
    "            if ((pd.isna(row['age'])) | (row['age'] > 115) | (row['age'] < 0)):\n",
    "                self.merged_data.at[i,'age'] = 2019 - year\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def removeOutliers(self):\n",
    "        # Remove outliers on floats datas\n",
    "        \n",
    "        ## Remove outliers from 'kurtosis_glucose'\n",
    "        column = 'kurtosis_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 6) | (self.merged_data[column] < -1)\n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'mean_glucose'\n",
    "        column = 'mean_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 150)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'mean_oxygen'\n",
    "        column = 'mean_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 120)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'kurtosis_oxygen'\n",
    "        column = 'kurtosis_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 20)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'skewness_glucose'\n",
    "        column = 'skewness_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 40)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'skewness_oxygen'\n",
    "        column = 'skewness_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 350)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'std_glucose'\n",
    "        column = 'std_glucose'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 62) \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "        \n",
    "        ## Remove outliers from 'std_oxygen'\n",
    "        column = 'std_oxygen'\n",
    "        # sns.boxplot(self.merged_data[column])\n",
    "        # self.merged_data[column].hist()\n",
    "        mask = (self.merged_data[column] > 80)  \n",
    "        self.merged_data.loc[mask ,column] = np.NaN\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def overtypeData(self):\n",
    "        # Change data type of object to float64\n",
    "        # From pipeline\n",
    "        \n",
    "        self.merged_data['age'] = self.merged_data['age'].astype(np.float64)\n",
    "        self.merged_data['education-num'] = self.merged_data['education-num'].astype(np.float64)\n",
    "        self.merged_data['capital-gain'] = self.merged_data['capital-gain'].astype(np.float64)\n",
    "        self.merged_data['fnlwgt'] = self.merged_data['fnlwgt'].astype(np.float64)\n",
    "        # self.merged_data['class'] = self.merged_data['class'].astype(np.float64)\n",
    "        self.merged_data['hours-per-week'] = self.merged_data['hours-per-week'].astype(np.float64)\n",
    "        self.merged_data['capital-loss'] = self.merged_data['capital-loss'].astype(np.float64)\n",
    "        self.merged_data['mean_glucose'] = self.merged_data['mean_glucose'].astype(np.float64)\n",
    "        self.merged_data['std_glucose'] = self.merged_data['std_glucose'].astype(np.float64)\n",
    "        self.merged_data['kurtosis_glucose'] = self.merged_data['kurtosis_glucose'].astype(np.float64)\n",
    "        self.merged_data['skewness_glucose'] = self.merged_data['skewness_glucose'].astype(np.float64)\n",
    "        self.merged_data['mean_oxygen'] = self.merged_data['mean_oxygen'].astype(np.float64)\n",
    "        self.merged_data['std_oxygen'] = self.merged_data['std_oxygen'].astype(np.float64)\n",
    "        self.merged_data['kurtosis_oxygen'] = self.merged_data['kurtosis_oxygen'].astype(np.float64)\n",
    "        self.merged_data['skewness_oxygen'] = self.merged_data['skewness_oxygen'].astype(np.float64)\n",
    "        self.merged_data['class'] = self.person['class']\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def divideData(self):\n",
    "        # Divide train data into 3 category\n",
    "        # Remove age and append on the end of DataFrame\n",
    "        # Remove class\n",
    "        \n",
    "        self.person['class'] = self.merged_data['class']\n",
    "        self.merged_data = self.merged_data.drop(columns=['class'])\n",
    "        age_column = copy.deepcopy(self.merged_data['age'])\n",
    "        self.merged_data = self.merged_data.drop(columns=['age'])\n",
    "        self.merged_data['age'] = age_column\n",
    "\n",
    "        numeric = self.merged_data.select_dtypes(include=['float64'])\n",
    "        self.numeric1 = numeric.iloc[:,:5].columns\n",
    "        # print(numeric1)\n",
    "        self.numeric2 = numeric.iloc[:,5:].columns\n",
    "        # print(numeric2)  \n",
    "        self.categoric = self.merged_data.select_dtypes(include=['object']).columns\n",
    "        # print(categoric)\n",
    "        return self\n",
    "    \n",
    "    def createPipelineSteps(self):\n",
    "        # Create pipeline steps, for categoric mostfrequent strategy\n",
    "        # For numeric KNN, MissForest\n",
    "        \n",
    "        numeric_transformer1 = Pipeline(steps=[('imputer',MissForest(missing_values=np.NaN, max_iter=10, # Nahradenie nulovych hodnot pomocou MissForest\n",
    "                                                                     decreasing=False, copy=False)), \n",
    "                                              ('powerTransformer',PowerTransformer(method='yeo-johnson',\n",
    "                                                                                   copy=False)) # Transformuje dat aby boli viac z Gaussoveho rozdelenia\n",
    "                                               ])\n",
    "        numeric_transformer2 = Pipeline(steps=[('imputer',KNNImputer(missing_values=np.NaN, n_neighbors=5, # Nahradenie nulovych hodnot pomocou KNN\n",
    "                                                                      weights='distance')), \n",
    "                                               \n",
    "                                               ])\n",
    "        self.categoric_transormer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))]) # Nahradenie nulovych hodnot pomocou najcastejsich hodnot\n",
    "                                              # ('onehot',OneHotEncoder(handle_unknown='ignore'))])\n",
    "        preproccesors = ColumnTransformer(transformers=[('Cat', self.categoric_transormer, self.categoric),\n",
    "                                                        ('Num1', numeric_transformer1, self.numeric1),\n",
    "                                                        ('Num2', numeric_transformer2, self.numeric2)\n",
    "                                                        ])\n",
    "        self.preproccessors = preproccesors\n",
    "        return self\n",
    "    \n",
    "    def createPipelineStepsMean(self):\n",
    "        # Create pipeline steps, for categoric mostfrequent strategy\n",
    "        # For numeric mean\n",
    "        \n",
    "        numeric_transformer1 = Pipeline(steps=[('imputer',SimpleImputer(strategy='mean'))])\n",
    "        self.categoric_transormer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))]) # Nahradenie nulovych hodnot pomocou najcastejsich hodnot\n",
    "        \n",
    "        preproccesors = ColumnTransformer(transformers=[('Cat', self.categoric_transormer, self.categoric),\n",
    "                                                        ('Num1', numeric_transformer1, self.numeric1),\n",
    "                                                        ('Num2', numeric_transformer1, self.numeric2)\n",
    "                                                        ])\n",
    "        self.preproccessors = preproccesors\n",
    "        return self\n",
    "    \n",
    "    def createPipelineStepsOnlyKNN(self):\n",
    "        # Create pipeline steps, for categoric mostfrequent strategy\n",
    "        # For numeric KNN\n",
    "    \n",
    "        numeric_transformer2 = Pipeline(steps=[('imputer',KNNImputer(missing_values=np.NaN, n_neighbors=5, # Nahradenie nulovych hodnot pomocou KNN\n",
    "                                                                      weights='distance'))])\n",
    "        self.categoric_transormer = Pipeline(steps=[('imputer',SimpleImputer(strategy='most_frequent'))]) # Nahradenie nulovych hodnot pomocou najcastejsich hodnot\n",
    "        \n",
    "        preproccesors = ColumnTransformer(transformers=[('Cat', self.categoric_transormer, self.categoric),\n",
    "                                                        ('Num1', numeric_transformer2, self.numeric1),\n",
    "                                                        ('Num2', numeric_transformer2, self.numeric2)\n",
    "                                                        ])\n",
    "        self.preproccessors = preproccesors\n",
    "        return self\n",
    "    \n",
    "    def appendPipelineSteps(self):\n",
    "        # Create Pipeline with steps\n",
    "        \n",
    "        if self.pipeline is None:\n",
    "            print(\"create Pipeline\")\n",
    "            self.pipeline = Pipeline(steps=[('preproccesors', self.preproccessors)])\n",
    "        else:\n",
    "            print(\"append Steps\")\n",
    "            self.pipeline.steps.append([('preproccesors', self.preproccessors)])\n",
    "        return self\n",
    "    \n",
    "    def popSteps(self):\n",
    "        self.pipeline.steps.pop()\n",
    "        return self\n",
    "    \n",
    "    def Fit(self):\n",
    "        # Use fit in pipeline\n",
    "        \n",
    "        self.pipeline.fit(self.merged_data)\n",
    "        # self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    \n",
    "    def FitTransform(self):\n",
    "        # Use fit and transform in pipeline\n",
    "        \n",
    "        pipeline_datas = self.pipeline.fit_transform(self.merged_data)\n",
    "        self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    \n",
    "    def Transform(self):\n",
    "        # Use transform in pipeline\n",
    "        \n",
    "        pipeline_datas = self.pipeline.transform(self.merged_data)\n",
    "        self.merged_data = pd.DataFrame(pipeline_datas,columns=self.merged_data.columns)\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:224: UserWarning: There are rows with more than 50.0% missing values. These rows are not included as donor neighbors.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "create Pipeline\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3933 entries, 0 to 3932\n",
      "Data columns (total 28 columns):\n",
      "name                3933 non-null object\n",
      "address             3933 non-null object\n",
      "sex                 3933 non-null object\n",
      "date_of_birth       3933 non-null object\n",
      "race                3933 non-null object\n",
      "marital-status      3933 non-null object\n",
      "occupation          3933 non-null object\n",
      "pregnant            3933 non-null object\n",
      "relationship        3933 non-null object\n",
      "education           3933 non-null object\n",
      "income              3933 non-null object\n",
      "native-country      3933 non-null object\n",
      "workclass           3933 non-null object\n",
      "education-num       3933 non-null float64\n",
      "capital-gain        3933 non-null float64\n",
      "fnlwgt              3933 non-null float64\n",
      "hours-per-week      3933 non-null float64\n",
      "capital-loss        3933 non-null float64\n",
      "kurtosis_glucose    3933 non-null float64\n",
      "kurtosis_oxygen     3933 non-null float64\n",
      "mean_glucose        3933 non-null float64\n",
      "mean_oxygen         3933 non-null float64\n",
      "skewness_glucose    3933 non-null float64\n",
      "skewness_oxygen     3933 non-null float64\n",
      "std_glucose         3933 non-null float64\n",
      "std_oxygen          3933 non-null float64\n",
      "age                 3933 non-null float64\n",
      "class               3933 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 860.4+ KB\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Data columns (total 28 columns):\n",
      "name                1311 non-null object\n",
      "address             1311 non-null object\n",
      "sex                 1311 non-null object\n",
      "date_of_birth       1311 non-null object\n",
      "race                1311 non-null object\n",
      "marital-status      1311 non-null object\n",
      "occupation          1311 non-null object\n",
      "pregnant            1311 non-null object\n",
      "relationship        1311 non-null object\n",
      "education           1311 non-null object\n",
      "income              1311 non-null object\n",
      "native-country      1311 non-null object\n",
      "workclass           1311 non-null object\n",
      "education-num       1311 non-null float64\n",
      "capital-gain        1311 non-null float64\n",
      "fnlwgt              1311 non-null float64\n",
      "hours-per-week      1311 non-null float64\n",
      "capital-loss        1311 non-null float64\n",
      "kurtosis_glucose    1311 non-null float64\n",
      "kurtosis_oxygen     1311 non-null float64\n",
      "mean_glucose        1311 non-null float64\n",
      "mean_oxygen         1311 non-null float64\n",
      "skewness_glucose    1311 non-null float64\n",
      "skewness_oxygen     1311 non-null float64\n",
      "std_glucose         1311 non-null float64\n",
      "std_oxygen          1311 non-null float64\n",
      "age                 1311 non-null float64\n",
      "class               1309 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 286.9+ KB\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1312 entries, 0 to 1311\n",
      "Data columns (total 28 columns):\n",
      "name                1312 non-null object\n",
      "address             1312 non-null object\n",
      "sex                 1312 non-null object\n",
      "date_of_birth       1312 non-null object\n",
      "native-country      1312 non-null object\n",
      "occupation          1312 non-null object\n",
      "relationship        1312 non-null object\n",
      "race                1312 non-null object\n",
      "income              1312 non-null object\n",
      "marital-status      1312 non-null object\n",
      "pregnant            1312 non-null object\n",
      "workclass           1312 non-null object\n",
      "education           1312 non-null object\n",
      "education-num       1312 non-null float64\n",
      "capital-loss        1312 non-null float64\n",
      "capital-gain        1312 non-null float64\n",
      "fnlwgt              1312 non-null float64\n",
      "hours-per-week      1312 non-null float64\n",
      "kurtosis_glucose    1312 non-null float64\n",
      "kurtosis_oxygen     1312 non-null float64\n",
      "mean_glucose        1312 non-null float64\n",
      "mean_oxygen         1312 non-null float64\n",
      "skewness_glucose    1312 non-null float64\n",
      "skewness_oxygen     1312 non-null float64\n",
      "std_glucose         1312 non-null float64\n",
      "std_oxygen          1312 non-null float64\n",
      "age                 1312 non-null float64\n",
      "class               0 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 287.1+ KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create new Dataset with KNN and MissForest\n",
    "# Load csv files\n",
    "\n",
    "data = pd.read_csv(\"../data/other_train.csv\",index_col=0)\n",
    "person = pd.read_csv(\"../data/personal_train.csv\",index_col=0)\n",
    "\n",
    "\n",
    "val_data = pd.read_csv(\"../data/other_valid.csv\",index_col=0)\n",
    "val_person = pd.read_csv(\"../data/personal_valid.csv\",index_col=0)\n",
    "\n",
    "test_data = pd.read_csv(\"../data/other_test.csv\",index_col=0)\n",
    "test_person = pd.read_csv(\"../data/personal_test.csv\",index_col=0)\n",
    "\n",
    "# Active train data processing\n",
    "\n",
    "wrapper = DataFrameWrapper(data,person)\n",
    "wrapper.prepocessing().removeOutliers().divideData().createPipelineSteps().appendPipelineSteps()\\\n",
    "                        .Fit().Transform()\n",
    "\n",
    "# Show training data, and save into trained_datas.csv\n",
    "\n",
    "merged_data = wrapper.overtypeData().getMergedData()\n",
    "merged_data.info()\n",
    "merged_data.to_csv('trained_datas.csv')\n",
    "\n",
    "# Use pipeline to transform on valid data\n",
    "\n",
    "wrapper.setPersonOtherData(val_data,val_person).prepocessing().removeOutliers().divideData()\n",
    "wrapper.Transform().overtypeData()\n",
    "\n",
    "\n",
    "# Show valid data. and save into validate_datas.csv\n",
    "\n",
    "wrapper.getMergedData().to_csv('validate_datas.csv')\n",
    "wrapper.getMergedData().info()\n",
    "\n",
    "\n",
    "# Use pipeline to transform test data\n",
    "\n",
    "wrapper.setPersonOtherData(test_data,test_person).prepocessing().removeOutliers()\n",
    "age_column = copy.deepcopy(wrapper.merged_data['age'])\n",
    "wrapper.merged_data = wrapper.merged_data.drop(columns=['age'])\n",
    "wrapper.merged_data['age'] = age_column\n",
    "wrapper.person['class'] = np.NaN\n",
    "wrapper.Transform().overtypeData()\n",
    "\n",
    "# Show test data. and save into test_datas.csv\n",
    "\n",
    "wrapper.getMergedData().to_csv('test_datas.csv')\n",
    "wrapper.getMergedData().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1970-10-10             2\n1961-04-27             2\n69-07-01               2\n1978-03-21             2\n1977-12-01             2\n1962-01-22             2\n1967-04-21             2\n1956-03-05             2\n1972-08-03             2\n1959-08-04             2\n1984-05-20             2\n1980-09-12             2\n1963-09-24             2\n1967-07-19             2\n1965-12-11             2\n1966-05-12             2\n1988-04-17             2\n1969-10-30             2\n1960-03-10             2\n1971-11-18             2\n1956-03-19             2\n1963-01-27             2\n1956-11-16             2\n1964-10-27             2\n1978-03-22             2\n1964-05-15             2\n1966-01-17             2\n1967-12-12             2\n1943-10-13             1\n08/01/1951             1\n                      ..\n1957-11-28             1\n1955-10-05             1\n1975-08-23             1\n29/04/1966             1\n1958-08-23             1\n1966-05-05             1\n70-10-05               1\n1966-08-21 00:00:00    1\n1974-08-24             1\n1946-06-01 00 00 00    1\n1965-06-03             1\n1967-11-28             1\n1956-11-01             1\n1966-10-06             1\n1966-05-10 00 00 00    1\n81-04-29               1\n1967-03-27             1\n1978/02/18             1\n04/07/1978             1\n1967-08-12             1\n63-06-04               1\n1957-09-26 00 00 00    1\n1956/06/27             1\n1966-02-09 00 00 00    1\n1969-02-17             1\n1969-03-24             1\n1962-05-09 00:00:00    1\n1968-01-13             1\n1967-06-09             1\n1974-05-30             1\nName: date_of_birth, Length: 1284, dtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "test_person['date_of_birth'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Vyskusame ine techniky na nahradzanie NaN hodnot, aby sme zistili ci tato cast ma vyplyv na konecne vysledky \n",
    "Vytvorili sme dve nove metody CreatePipelineStepsOnlyKNN (na nahradenie NaN hodnot\n",
    "pouzije len KNN algoritmus), CreatePipelineStepsMean (na nahradenie sa nepouzije miss\n",
    "forest, ale mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "create Pipeline\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3933 entries, 0 to 3932\n",
      "Data columns (total 28 columns):\n",
      "name                3933 non-null object\n",
      "address             3933 non-null object\n",
      "sex                 3933 non-null object\n",
      "date_of_birth       3933 non-null object\n",
      "race                3933 non-null object\n",
      "marital-status      3933 non-null object\n",
      "occupation          3933 non-null object\n",
      "pregnant            3933 non-null object\n",
      "relationship        3933 non-null object\n",
      "education           3933 non-null object\n",
      "income              3933 non-null object\n",
      "native-country      3933 non-null object\n",
      "workclass           3933 non-null object\n",
      "education-num       3933 non-null float64\n",
      "capital-gain        3933 non-null float64\n",
      "fnlwgt              3933 non-null float64\n",
      "hours-per-week      3933 non-null float64\n",
      "capital-loss        3933 non-null float64\n",
      "kurtosis_glucose    3933 non-null float64\n",
      "kurtosis_oxygen     3933 non-null float64\n",
      "mean_glucose        3933 non-null float64\n",
      "mean_oxygen         3933 non-null float64\n",
      "skewness_glucose    3933 non-null float64\n",
      "skewness_oxygen     3933 non-null float64\n",
      "std_glucose         3933 non-null float64\n",
      "std_oxygen          3933 non-null float64\n",
      "age                 3933 non-null float64\n",
      "class               3933 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 860.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Data columns (total 28 columns):\n",
      "name                1311 non-null object\n",
      "address             1311 non-null object\n",
      "sex                 1311 non-null object\n",
      "date_of_birth       1311 non-null object\n",
      "race                1311 non-null object\n",
      "marital-status      1311 non-null object\n",
      "occupation          1311 non-null object\n",
      "pregnant            1311 non-null object\n",
      "relationship        1311 non-null object\n",
      "education           1311 non-null object\n",
      "income              1311 non-null object\n",
      "native-country      1311 non-null object\n",
      "workclass           1311 non-null object\n",
      "education-num       1311 non-null float64\n",
      "capital-gain        1311 non-null float64\n",
      "fnlwgt              1311 non-null float64\n",
      "hours-per-week      1311 non-null float64\n",
      "capital-loss        1311 non-null float64\n",
      "kurtosis_glucose    1311 non-null float64\n",
      "kurtosis_oxygen     1311 non-null float64\n",
      "mean_glucose        1311 non-null float64\n",
      "mean_oxygen         1311 non-null float64\n",
      "skewness_glucose    1311 non-null float64\n",
      "skewness_oxygen     1311 non-null float64\n",
      "std_glucose         1311 non-null float64\n",
      "std_oxygen          1311 non-null float64\n",
      "age                 1311 non-null float64\n",
      "class               1309 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 286.9+ KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create new Dataset with only mean\n",
    "# Load csv files\n",
    "\n",
    "data = pd.read_csv(\"../data/other_train.csv\",index_col=0)\n",
    "person = pd.read_csv(\"../data/personal_train.csv\",index_col=0)\n",
    "\n",
    "\n",
    "val_data = pd.read_csv(\"../data/other_valid.csv\",index_col=0)\n",
    "val_person = pd.read_csv(\"../data/personal_valid.csv\",index_col=0)\n",
    "\n",
    "wrapper = DataFrameWrapper(data,person)\n",
    "wrapper.prepocessing().removeOutliers().divideData().createPipelineStepsMean().appendPipelineSteps()\\\n",
    "                        .Fit().Transform()\n",
    "\n",
    "# Show training data, and save into trained_datas.csv\n",
    "\n",
    "merged_data = wrapper.overtypeData().getMergedData()\n",
    "merged_data.info()\n",
    "merged_data.to_csv('trained_datas_mean.csv')\n",
    "\n",
    "# Use pipeline to transform on valid data\n",
    "\n",
    "wrapper.setPersonOtherData(val_data,val_person).prepocessing().removeOutliers().divideData()\n",
    "wrapper.Transform().overtypeData()\n",
    "\n",
    "\n",
    "# Show valid data. and save into validate_datas.csv\n",
    "\n",
    "wrapper.getMergedData().to_csv('validate_datas_mean.csv')\n",
    "wrapper.getMergedData().info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:224: UserWarning: There are rows with more than 50.0% missing values. These rows are not included as donor neighbors.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/utils.py:124: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/missingpy/knnimpute.py:282: UserWarning: There are rows with more than 50.0% missing values. The missing features in these rows are imputed with column means.\n",
      "  .format(self.row_max_missing * 100))\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "/home/matho/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "create Pipeline\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3933 entries, 0 to 3932\n",
      "Data columns (total 28 columns):\n",
      "name                3933 non-null object\n",
      "address             3933 non-null object\n",
      "sex                 3933 non-null object\n",
      "date_of_birth       3933 non-null object\n",
      "race                3933 non-null object\n",
      "marital-status      3933 non-null object\n",
      "occupation          3933 non-null object\n",
      "pregnant            3933 non-null object\n",
      "relationship        3933 non-null object\n",
      "education           3933 non-null object\n",
      "income              3933 non-null object\n",
      "native-country      3933 non-null object\n",
      "workclass           3933 non-null object\n",
      "education-num       3933 non-null float64\n",
      "capital-gain        3933 non-null float64\n",
      "fnlwgt              3933 non-null float64\n",
      "hours-per-week      3933 non-null float64\n",
      "capital-loss        3933 non-null float64\n",
      "kurtosis_glucose    3933 non-null float64\n",
      "kurtosis_oxygen     3933 non-null float64\n",
      "mean_glucose        3933 non-null float64\n",
      "mean_oxygen         3933 non-null float64\n",
      "skewness_glucose    3933 non-null float64\n",
      "skewness_oxygen     3933 non-null float64\n",
      "std_glucose         3933 non-null float64\n",
      "std_oxygen          3933 non-null float64\n",
      "age                 3933 non-null float64\n",
      "class               3933 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 860.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Data columns (total 28 columns):\n",
      "name                1311 non-null object\n",
      "address             1311 non-null object\n",
      "sex                 1311 non-null object\n",
      "date_of_birth       1311 non-null object\n",
      "race                1311 non-null object\n",
      "marital-status      1311 non-null object\n",
      "occupation          1311 non-null object\n",
      "pregnant            1311 non-null object\n",
      "relationship        1311 non-null object\n",
      "education           1311 non-null object\n",
      "income              1311 non-null object\n",
      "native-country      1311 non-null object\n",
      "workclass           1311 non-null object\n",
      "education-num       1311 non-null float64\n",
      "capital-gain        1311 non-null float64\n",
      "fnlwgt              1311 non-null float64\n",
      "hours-per-week      1311 non-null float64\n",
      "capital-loss        1311 non-null float64\n",
      "kurtosis_glucose    1311 non-null float64\n",
      "kurtosis_oxygen     1311 non-null float64\n",
      "mean_glucose        1311 non-null float64\n",
      "mean_oxygen         1311 non-null float64\n",
      "skewness_glucose    1311 non-null float64\n",
      "skewness_oxygen     1311 non-null float64\n",
      "std_glucose         1311 non-null float64\n",
      "std_oxygen          1311 non-null float64\n",
      "age                 1311 non-null float64\n",
      "class               1309 non-null float64\n",
      "dtypes: float64(15), object(13)\n",
      "memory usage: 286.9+ KB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create new Dataset with only KNN algorithm\n",
    "# Load csv files\n",
    "\n",
    "data = pd.read_csv(\"../data/other_train.csv\",index_col=0)\n",
    "person = pd.read_csv(\"../data/personal_train.csv\",index_col=0)\n",
    "\n",
    "\n",
    "val_data = pd.read_csv(\"../data/other_valid.csv\",index_col=0)\n",
    "val_person = pd.read_csv(\"../data/personal_valid.csv\",index_col=0)\n",
    "\n",
    "wrapper = DataFrameWrapper(data,person)\n",
    "wrapper.prepocessing().removeOutliers().divideData().createPipelineStepsOnlyKNN().appendPipelineSteps()\\\n",
    "                        .Fit().Transform()\n",
    "\n",
    "# Show training data, and save into trained_datas.csv\n",
    "\n",
    "merged_data = wrapper.overtypeData().getMergedData()\n",
    "merged_data.info()\n",
    "merged_data.to_csv('trained_datas_KNN.csv')\n",
    "\n",
    "# Use pipeline to transform on valid data\n",
    "\n",
    "wrapper.setPersonOtherData(val_data,val_person).prepocessing().removeOutliers().divideData()\n",
    "wrapper.Transform().overtypeData()\n",
    "\n",
    "\n",
    "# Show valid data. and save into validate_datas.csv\n",
    "\n",
    "wrapper.getMergedData().to_csv('validate_datas_KNN.csv')\n",
    "wrapper.getMergedData().info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalne zhodnotenie jednotlivych vytvorenych stromov\n",
    "\n",
    "Oproti natrenovanemu stromu pomocou kniznice scikit-learn, nas komplikovany strom (ktory dosiahol lepsie hodnoty ako jednoduchy) dosiahol lepsie vysledky precision a accuracy, ale recall bol o nieco horsi.\n",
    "\n",
    "* Jednoduchy strom \"nas\" : precision 90.3%, recall 89.5% a accuracy 92.2%\n",
    "* Komplikovany strom \"nas\" : precision 96.2%, recall 92% a accuracy 95.4%\n",
    "* Natrenovany strom \"scikit-learn\" : precision 91.3%, recall 93.3% a accuracy 93.8%\n",
    "* Natrenovany strom \"vytunene hyperparametre\" : precision 95.5%, recall 94.4% a accuracy 96.1%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-938d843a",
   "language": "python",
   "display_name": "PyCharm (IAU)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}